dat$subjectID <- as.factor(dat$subjectID)
summary(dat$subjectID)
dat$subjectID %>% unique %>% length
dat$complementizer <- as.character(dat$complementizer)
dat$complementizer <- as.character(dat$complementizer)
dat$complementizer[dat$complementizer == "2-Jul"] <- "jul2"
dat$complementizer[dat$complementizer == "1-Jul"] <- "jul1"
dat$complementizer <- as.factor(dat$complementizer)
summary(dat$complementizer)
dat_t <-
dat %>%
filter(complementizer != "ctr",
complementizer != "geo1",
complementizer != "geo2",
prosody != "p3")
summary(dat_t$verbtype)
# Order verbs in intuitive pairs
dat_t$verbtype <- factor(dat_t$verbtype, levels= c("al","moreu", "gieok", "ggameok", "mit", "alanae"))
summary(dat_t$verbtype)
dat_t$prosody <- as.character(dat_t$prosody)
dat_t$prosody[dat_t$prosody == "p1"] <- "ES"
dat_t$prosody[dat_t$prosody == "p2"] <- "EV"
dat_t$prosody[dat_t$prosody == "p4"] <- "MV"
dat_t$prosody <- as.factor(dat_t$prosody)
summary(dat_t$prosody)
dat_s1 <-
dat_t %>%
group_by(verbtype) %>%
summarise(meanVer = mean(veridicality))
dat_s1
dat_s1 <-
dat_t %>%
group_by(verbtype) %>%
summarise(meanVer = mean(veridicality))
dat_s1
dat_s2 <- dat_t %>%
group_by(verbtype, prosody) %>%
summarise(meanVer = mean(veridicality))
dat_s2
dat_s3 <- dat_t %>%
group_by(verbtype, prosody, complementizer) %>%
summarise(meanVer = mean(veridicality))
dat_s3
?geom_boxplot
dat_t %>%
ggplot(aes(x = verbtype, y = veridicality, col = prosody)) +
geom_boxplot()
dat_t %>%
ggplot(aes(x = verbtype, y = veridicality, col = prosody)) +
geom_boxplot() +
facet_grid(. ~ complementizer)
dat_t %>%
ggplot(aes(x = verbtype, y = veridicality)) +
geom_boxplot() +
facet_grid(prosody ~ complementizer)
p1 <- dat_t %>%
ggplot(aes(x = verbtype, y = veridicality, col = prosody)) +
geom_boxplot()
p1
dat_s3 <- dat_t %>%
group_by(verbtype, prosody, complementizer) %>%
summarise(meanVer = mean(veridicality))
dat_s3
dat_s3
dat_s3 %>%
ggplot(aes(x = prosody, y = meanVer, fill = prosody)) +
geom_bar(stat = "identity") +
facet_grid(complementizer ~ verbtype)
dat_s <- dat_t %>%
group_by(verbtype, complementizer, prosody) %>%
summarise(meanVer = mean(veridicality),
n = n(),
# Standard deviations
sdVer = sd(veridicality),
# Standard errors
seVer = sdVer/sqrt(n))
dat_s
View(dat_s)
dat_s <- dat_t %>%
group_by(verbtype, complementizer, prosody) %>%
summarise(meanNat = mean(naturalness),
meanVer = mean(veridicality),
n = n(),
# Standard deviations
sdNat = sd(naturalness),
sdVer = sd(veridicality),
# Standard errors
seNat = sdNat/sqrt(n),
seVer = sdVer/sqrt(n))
dat_s
View(dat_s)
dat_t$complementizer2 <- dat_t$complementizer
dat_t$complementizer2 <- as.character(dat_t$complementizer2)
dat_t$complementizer2[dat_t$complementizer2 == "jul1"] <- "jul"
dat_t$complementizer2[dat_t$complementizer2 == "jul2"] <- "jul"
dat_t$complementizer2 <- as.factor(dat_t$complementizer2)
# Order complementizers in intuitive pairs
dat_t$complementizer2 <- factor(dat_t$complementizer2, levels= c("jul","go"))
dat_s <- dat_t %>%
group_by(verbtype, complementizer2, prosody) %>%
summarise(meanNat = mean(naturalness),
meanVer = mean(veridicality),
n = n(),
sdNat = sd(naturalness),
sdVer = sd(veridicality),
seNat = sdNat/sqrt(n),
seVer = sdVer/sqrt(n))
dat_s
dat_s %>%
ggplot(aes(x = prosody, y = meanVer, fill = prosody)) +
geom_bar(stat = "identity") +
geom_errorbar(aes(ymin=meanVer-seVer, ymax=meanVer+seVer),
width=.2,                    # Width of the error bars
position=position_dodge(.9)) +
facet_grid(complementizer2 ~ verbtype)
p <- dat_s %>%
ggplot(aes(x = prosody, y = meanVer, fill = prosody)) +
geom_bar(stat = "identity") +
geom_errorbar(aes(ymin=meanVer-seVer, ymax=meanVer+seVer),
width=.2,                    # Width of the error bars
position=position_dodge(.9)) +
facet_grid(complementizer2 ~ verbtype) +
ggthemes::theme_few() +
scale_fill_manual(values = wes_palette("GrandBudapest2"))
p
p <- dat_s %>%
ggplot(aes(x = prosody, y = meanVer, fill = prosody)) +
geom_bar(stat = "identity") +
geom_errorbar(aes(ymin=meanVer-seVer, ymax=meanVer+seVer),
width=.2,                    # Width of the error bars
position=position_dodge(.9)) +
facet_grid(complementizer2 ~ verbtype) +
theme_bw() +
theme(axis.title.y=element_text(size=14),
axis.title.x=element_blank()) + labs(y='Mean Veridicality Ratings') +
scale_fill_manual(values = c("#D55E00", "#009E73", "#56B4E9")) +
theme(legend.position="none") +
theme(strip.text.x = element_text(size = 10), strip.text.y = element_text(size = 10)) +
geom_hline(yintercept=true_base, linetype="dashed",
color = "#F0E442", size=1.2) +
geom_hline(yintercept=false_base, linetype="dashed",
color = "#999999", size=1.2)
p
## Call this in whenever you want to use associated packages such as ggplot2, tidyr, etc.
library(tidyverse)
dat <- read.csv('veridicality-pilot-data-191127.csv')
head(dat)
## Call this in whenever you want to use associated packages such as ggplot2, tidyr, etc.
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
## The data
dat <- read.csv('veridicality-pilot-data-191127.csv')
head(dat)
## Inspect
summary(dat$complementizer)
summary(dat$prosody)
summary(dat$item)
dat$complementizer <- as.character(dat$complementizer)
dat$complementizer[dat$complementizer == "2-Jul"] <- "jul2"
dat$complementizer[dat$complementizer == "1-Jul"] <- "jul1"
dat$complementizer <- as.factor(dat$complementizer)
dat_t <-
dat %>%
filter(complementizer != "ctr",
complementizer != "geo1",
complementizer != "geo2",
prosody != "p3")
# Order verbs in intuitive pairs
dat_t$verbtype <- factor(dat_t$verbtype, levels= c("al","moreu", "gieok", "ggameok", "mit", "alanae"))
# Rename the prosody conditions in more intuitive ways
dat_t$prosody <- as.character(dat_t$prosody)
dat_t$prosody[dat_t$prosody == "p1"] <- "ES"
dat_t$prosody[dat_t$prosody == "p2"] <- "EV"
dat_t$prosody[dat_t$prosody == "p4"] <- "MV"
dat_t$prosody <- as.factor(dat_t$prosody)
?write.csv
# Save cleaned data
write.csv(dat_t, file = "veridicality-target-cleaned.csv")
## The data: target data is a .csv containing the cleaned target data from the previous tutorial
dat <- read.csv('veridicality-target-cleaned.csv')
head(dat)
summary(dat$veridicality)
dat$veridicality <- as.factor(dat$veridicality)
summary(dat$veridicality)
head(dat)
sum_dat <- dat %>%
group_by(veridicality, verbtype, complementizer, prosody) %>%
summarise(count=n()) %>%
mutate(perc=count/sum(count), n=sum(count))
sum_dat
View(sum_dat)
sum_dat %>%
ggplot(aes(x = verbtype, y = perc, col = prosody)) +
geom_bar() +
facet_grid(. ~ complementizer)
sum_dat %>%
ggplot(aes(x = verbtype, y = perc)) +
geom_bar() +
facet_grid(prosody ~ complementizer)
sum_dat <- dat %>%
group_by(verbtype, complementizer, prosody, veridicality) %>%
summarise(count=n()) %>%
mutate(perc=count/sum(count), n=sum(count))
View(sum_dat)
sum_dat %>%
ggplot(aes(x = verbtype, y = perc, fill = veridicality)) +
geom_bar() +
facet_grid(prosody ~ complementizer)
sum_dat %>%
ggplot(aes(x = verbtype, y = perc, fill = veridicality)) +
geom_bar(stat = "identity") +
facet_grid(prosody ~ complementizer)
p <- sum_dat %>%
ggplot(aes(x = verbtype, y = perc, fill = veridicality)) +
geom_bar(stat = "identity") +
facet_grid(prosody ~ complementizer)
p
install.packages("lmerTest")
dat <- read.csv('veridicality-target-cleaned.csv')
head(dat)
View(dat)
## First, make sure that R treats relevant dependent variables as factors
summary(dat$veridicality)
dat$veridicality <- as.factor(dat$veridicality)
summary(dat$veridicality)
sum_dat <- dat %>%
group_by(verbtype, complementizer, prosody, veridicality) %>%
summarise(count=n()) %>%
mutate(perc=count/sum(count), n=sum(count))
View(sum_dat)
p <- sum_dat %>%
ggplot(aes(x = verbtype, y = perc, fill = veridicality)) +
geom_bar(stat = "identity") +
facet_grid(prosody ~ complementizer)
p
library(lme4)
library(lmerTest)
datv <- read.csv('asmt1-korean-vowels.csv')
head(datv)
## Call this in whenever you want to use associated packages such as ggplot2, tidyr, etc.
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
## The data: target data is a .csv containing the cleaned target data from the previous tutorial
dat <- read.csv('veridicality-target-cleaned.csv')
head(dat)
## First, make sure that R treats relevant dependent variables as factors
summary(dat$veridicality)
dat$veridicality <- as.factor(dat$veridicality)
summary(dat$veridicality)
m2 <- lm(F0 ~ ht + sp_gender + wpos + vpos, data=datv)
summary(m2)
## Call this in whenever you want to use associated packages such as ggplot2, tidyr, etc.
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
## The data: target data is a .csv containing the cleaned target data from the previous tutorial
dat <- read.csv('veridicality-target-cleaned.csv')
head(dat)
## First, make sure that R treats relevant dependent variables as factors
summary(dat$veridicality)
dat$veridicality <- as.factor(dat$veridicality)
summary(dat$veridicality)
dat_jul <-
dat %>%
filter(complementizer == "jul1",
complementizer == "jul2")
dat_jul$veridicality <- as.factor(dat_jul$veridicality)
m1 <- clmm(veridicality ~ prosody * verbtype + (1|item) + (1|uniqueIdentifier), data=dat_jul)
## Call this in whenever you want to use associated packages such as ggplot2, tidyr, etc.
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
## The data: target data is a .csv containing the cleaned target data from the previous tutorial
dat <- read.csv('veridicality-target-cleaned.csv')
head(dat)
## First, make sure that R treats relevant dependent variables as factors
summary(dat$veridicality)
dat$veridicality <- as.factor(dat$veridicality)
summary(dat$veridicality)
library(ordinal)
m1 <- clmm(veridicality ~ prosody * verbtype + (1|item) + (1|uniqueIdentifier), data=dat_jul)
## Call this in whenever you want to use associated packages such as ggplot2, tidyr, etc.
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
## The data: target data is a .csv containing the cleaned target data from the previous tutorial
dat <- read.csv('veridicality-target-cleaned.csv')
head(dat)
## First, make sure that R treats relevant dependent variables as factors
summary(dat$veridicality)
dat$veridicality <- as.factor(dat$veridicality)
summary(dat$veridicality)
m1 <- clmm(veridicality ~ prosody * verbtype + (1|item) + (1|subjectID), data=dat_jul)
dat <- read.csv('gendered-TAs-pilot1-cleaned.csv')
View(dat)
View(dat)
sum_tultul <- dat %>%
group_by(matchtype, speaker, hearer) %>%
summarise(meantul = mean(tultul))
View(sum_tultul)
sum_tultul %>%
ggplot(aes(x = matchtype, y = meantul, col = matchtype)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ hearer)
sum_tultul %>%
ggplot(aes(x = matchtype, y = meantul, col = matchtype)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ .)
sum_tultul %>%
ggplot(aes(x = matchtype, y = meantul, col = matchtype)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ hearer)
sum_aegyo <- dat %>%
group_by(matchtype, speaker, hearer) %>%
summarise(meanaeg = mean(aegyo))
## aegyo visualization
sum_aegyo %>%
ggplot(aes(x = matchtype, y = meanaeg, col = matchtype)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ hearer) #vertical/column: speaker, horizontal/row: hearer
sum_tultul2 <- dat %>%
group_by(address, speaker) %>%
summarise(meantul2 = mean(tultul))
## tultul visualization by mismatch type and speaker/hearer gender
sum_tultul2 %>%
ggplot(aes(x = address, y = meantul2, col = address)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ .) #vertical/column: speaker, horizontal/row: hearer
## Creating count/percent summary
## tultul summary by mismatch type and speaker/hearer gender
sum_tultul <- dat %>%
group_by(matchtype, speaker, hearer) %>%
summarise(meantul = mean(tultul))
## tultul visualization by mismatch type and speaker/hearer gender
sum_tultul %>%
ggplot(aes(x = matchtype, y = meantul, col = matchtype)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ hearer) #vertical/column: speaker, horizontal/row: hearer
## tultul summary by address type and speaker gender
sum_tultul2 <- dat %>%
group_by(address, speaker) %>%
summarise(meantul2 = mean(tultul))
## tultul visualization by mismatch type and speaker/hearer gender
sum_tultul2 %>%
ggplot(aes(x = address, y = meantul2, col = address)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ .) #vertical/column: speaker, horizontal/row: hearer
## aegyo
sum_aegyo <- dat %>%
group_by(matchtype, speaker, hearer) %>%
summarise(meanaeg = mean(aegyo))
## aegyo visualization
sum_aegyo %>%
ggplot(aes(x = matchtype, y = meanaeg, col = matchtype)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ hearer) #vertical/column: speaker, horizontal/row: hearer
## femininity
sum_aegyo <- dat %>%
group_by(matchtype, speaker, hearer) %>%
summarise(meanaeg = mean(aegyo))
## aegyo visualization
sum_aegyo %>%
ggplot(aes(x = matchtype, y = meanaeg, col = matchtype)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ hearer) #vertical/column: speaker, horizontal/row: hearer
## Call this in whenever you want to use associated packages such as ggplot2, tidyr, etc.
## install.packages("tidyverse")
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE, cache=TRUE)
dat <- read.csv('gendered-TAs-pilot1-cleaned.csv')
p2 <- sum_tultul2 %>%
ggplot(aes(x = address, y = meantul2, col = address)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ .) #vertical/column: speaker, horizontal/row: hearer
p2
p2
sum_aegyo2 <- dat %>%
group_by(address, speaker) %>%
summarise(meanaeg2 = mean(aegyo))
## aegyo visualization by address type and speaker gender
p2 <- sum_aegyo2 %>%
ggplot(aes(x = address, y = meanaeg2, col = address)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ .) #vertical/column: speaker, horizontal/row: hearer
p2
p2
sum_aegyo3 <- dat %>%
group_by(address, speaker, hearer) %>%
summarise(meanaeg3 = mean(aegyo))
## aegyo visualization by address type and speaker gender
p3 <- sum_aegyo3 %>%
ggplot(aes(x = address, y = meanaeg3, col = address)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ hearer) #vertical/column: speaker, horizontal/row: hearer
p3
p3
sum_partner <- dat %>%
group_by(address, speaker, hearer) %>%
summarise(meanpart = mean(partner))
## tultul visualization by mismatch type and speaker/hearer gender
sum_partner %>%
ggplot(aes(x = address, y = meanpart, col = address)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ hearer)
## Creating count/percent summary
## tultul summary by mismatch type and speaker/hearer gender
sum_partner <- dat %>%
group_by(address, speaker, hearer) %>%
summarise(meanpart = mean(partner))
## tultul visualization by mismatch type and speaker/hearer gender
sum_partner %>%
ggplot(aes(x = address, y = meanpart, col = address)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ hearer) #vertical/column: speaker, horizontal/row: hearer
View(sum_partner)
sum_address <- dat %>%
group_by(address) %>%
summarise(meansib = mean(sibling),
meanpart = mean(partner),
meanclfr = mean(clfriend),
meanwkfr = mean(wkfriend),
meanacq = mean(acquaintance),
meanstr = mean(stranger))
View(sum_address)
sum_address2 <-
sum_address %>% gather(relationship, likelihood, -address)
View(sum_address2)
p <- sum_address2 %>%
ggplot(aes(x = address, y = likelihood, col = address)) +
geom_bar(stat = "identity") +
facet_grid(relationship ~ .)
p
dat <- read.csv('gendered-TAs-pilot-200610.csv')
dat <- read.csv('gendered-tas-pilot-200610.csv')
dat <- read.csv('gendered-tas-pilot-200610.csv')
dat <- read.csv('gendered-TAs-pilot1-cleaned.csv')
dat <- read.csv('gendered-tas-pilot-200610-2.csv')
summary(dat)
summary(dat$matchtype)
dat$matchtype <- as.character(dat$matchtype)
dat$matchtype[dat$matchtype == "0"] <- "na"
dat$matchtype <- as.factor(dat$matchtype)
summary(dat$matchtype)
summary(dat$address)
dat$address <- as.character(dat$address)
dat$address[dat$address == "0"] <- "na"
dat$address <- as.factor(dat$address)
summary(dat$address)
write.csv(dat, file = "gendered-tas-cleaned-200610.csv")
# Start here
dat <- read.csv('gendered-tas-cleaned-200610.csv')
sum_tultul <- dat %>%
group_by(matchtype, speaker, hearer) %>%
summarise(meantul = mean(tultul))
## tultul visualization by mismatch type and speaker/hearer gender
sum_tultul %>%
ggplot(aes(x = matchtype, y = meantul, col = matchtype)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ hearer) #vertical/column: speaker, horizontal/row: hearer
## tultul summary by address type and speaker gender
sum_tultul2 <- dat %>%
group_by(address, speaker) %>%
summarise(meantul2 = mean(tultul))
## tultul visualization by mismatch type and speaker/hearer gender
p2 <- sum_tultul2 %>%
ggplot(aes(x = address, y = meantul2, col = address)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ .) #vertical/column: speaker, horizontal/row: hearer
p2
p2
sum_aegyo2 <- dat %>%
group_by(address, speaker) %>%
summarise(meanaeg2 = mean(aegyo))
## aegyo visualization by address type and speaker gender
p2 <- sum_aegyo2 %>%
ggplot(aes(x = address, y = meanaeg2, col = address)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ .) #vertical/column: speaker, horizontal/row: hearer
p2
p2
sum_partner <- dat %>%
group_by(address, speaker, hearer) %>%
summarise(meanpart = mean(partner))
## partner visualization by address type and speaker/hearer gender
sum_partner %>%
ggplot(aes(x = address, y = meanpart, col = address)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ hearer)
## Creating count/percent summary
## partner summary by address type and speaker/hearer gender
sum_partner <- dat %>%
group_by(address, speaker, hearer) %>%
summarise(meanpart = mean(partner))
## partner visualization by address type and speaker/hearer gender
sum_partner %>%
ggplot(aes(x = address, y = meanpart, col = address)) +
geom_bar(stat = "identity") +
facet_grid(speaker ~ hearer) #vertical/column: speaker, horizontal/row: hearer
## matching terms most likely to signal partner in case of F-M, M-F (heterosexual) relationships;
## 'oppa' most likely to signal partner in case of F-F, M-M
## Overview of all speaker-hearer relationships according to address type
sum_address <- dat %>%
group_by(address) %>%
summarise(meansib = mean(sibling),
meanpart = mean(partner),
meanclfr = mean(clfriend),
meanwkfr = mean(wkfriend),
meanacq = mean(acquaintance),
meanstr = mean(stranger))
sum_address2 <-
sum_address %>% gather(relationship, likelihood, -address)
p <- sum_address2 %>%
ggplot(aes(x = address, y = likelihood, col = address)) +
geom_bar(stat = "identity") +
facet_grid(relationship ~ .)
